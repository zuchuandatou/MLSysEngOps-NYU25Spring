{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MLFlow outside of training runs\n",
    "\n",
    "We can interact with the MLFLow tracking service through the web-based UI, but we can also use its Python API. For example, we can systematically “promote” the model from the highest-scoring run as the registered model, and then trigger a CI/CD pipeline using the new model.\n",
    "\n",
    "After completing this section, you should be able to:\n",
    "\n",
    "-   use the MLFlow Python API to search runs\n",
    "-   and use the MLFlow Python API to interact with the model registry\n",
    "\n",
    "The code in this notebook will run in the “jupyter” container on “node-mltrain”. Inside the “work” directory in your Jupyter container on “node-mltrain”, open the `mlflow_api.ipynb` notebook, and follow along there to execute this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s create an MLFlow client and connect to our tracking server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# We don't have to set MLflow tracking URI because we set it in an environment variable\n",
    "# mlflow.set_tracking_uri(\"http://A.B.C.D:8000/\") \n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s specify get the ID of the experiment we are interesting in searching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name(\"food11-classifier\")\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use this experiment ID to query our experiment runs. Let’s ask MLFlow to return the two runs with the largest value of the `test_accuracy` metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id], \n",
    "    order_by=[\"metrics.test_accuracy DESC\"], \n",
    "    max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these are sorted, the first element in `runs` should be the run with the highest accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = runs[0]  # The first run is the best due to sorting\n",
    "best_run_id = best_run.info.run_id\n",
    "best_test_accuracy = best_run.data.metrics[\"test_accuracy\"]\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "\n",
    "print(f\"Best Run ID: {best_run_id}\")\n",
    "print(f\"Test Accuracy: {best_test_accuracy}\")\n",
    "print(f\"Model URI: {model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s register this model in the MLFlow model registry. We’ll call it “food11-staging”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"food11-staging\"\n",
    "registered_model = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "print(f\"Model registered as '{model_name}', version {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, we should see it if we click on the “Models” section of the MLFlow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s imagine that a separate process - for example, part of a CI/CD pipeline - wants to download the latest version of the “food11-staging” model, in order to build a container including this model and deploy it to a staging environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# We don't have to set MLflow tracking URI because we set it in an environment variable\n",
    "# mlflow.set_tracking_uri(\"http://A.B.C.D:8000/\") \n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"food11-staging\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get all versions of the “food11-staging” model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the version with the highest version number (latest version):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_version = max(model_versions, key=lambda v: int(v.version))\n",
    "\n",
    "print(f\"Latest registered version: {latest_version.version}\")\n",
    "print(f\"Model Source: {latest_version.source}\")\n",
    "print(f\"Status: {latest_version.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now, we can download the model artifact (e.g. in order to build it into a Docker container):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_download = mlflow.artifacts.download_artifacts(latest_version.source, dst_path=\"./downloaded_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file browser on the left side, note that the “downloaded_model” directory has appeared, and the model has been downloaded from the registry into this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop MLFlow system\n",
    "\n",
    "When you are finished with this section, stop the MLFlow tracking server and its associated pieces (database, object store) with\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker compose -f mltrain-chi/docker/docker-compose-mlflow.yaml down\n",
    "```\n",
    "\n",
    "and then stop the Jupyter server with\n",
    "\n",
    "``` bash\n",
    "# run on node-mltrain\n",
    "docker stop jupyter\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
