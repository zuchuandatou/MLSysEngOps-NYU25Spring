{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0154729",
   "metadata": {},
   "source": [
    "# Inference Performance Summary\n",
    "### 1. PyTorch Model on CPU (Eager Mode)\n",
    "Model Size on Disk: 5.56 MB\n",
    "\n",
    "Single Sample Latency (Median): 4.08 ms\n",
    "\n",
    "Inference Latency (Median): 4.08 ms\n",
    "\n",
    "Inference Latency (95th Percentile): 4.53 ms\n",
    "\n",
    "Inference Latency (99th Percentile): 4.86 ms\n",
    "\n",
    "Throughput (Single Sample): 239.77 FPS\n",
    "\n",
    "Batch Throughput: 3973.37 FPS\n",
    "\n",
    "### 2. PyTorch Model on CPU (Compiled Mode)\n",
    "Model Size on Disk: 5.56 MB\n",
    "\n",
    "Single Sample Latency (Median): 3.19 ms\n",
    "\n",
    "Inference Latency (Median): 3.19 ms\n",
    "\n",
    "Inference Latency (95th Percentile): 3.63 ms\n",
    "\n",
    "Inference Latency (99th Percentile): 112.37 ms\n",
    "\n",
    "Throughput (Single Sample): 9.86 FPS\n",
    "\n",
    "Batch Throughput: 5381.72 FPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14c5fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd281a6",
   "metadata": {},
   "source": [
    "## Apply Optimizations to ONNX Model\n",
    "### 3. Graph Optimizations\n",
    "Execution Provider: ['CPUExecutionProvider']\n",
    "\n",
    "Inference Latency (Median): 1.91 ms\n",
    "\n",
    "Inference Latency (95th Percentile): 1.93 ms\n",
    "\n",
    "Inference Latency (99th Percentile): 2.19 ms\n",
    "\n",
    "Inference Throughput (Single Sample): 522.37 FPS\n",
    "\n",
    "Batch Throughput: 1072.27 FPS\n",
    "\n",
    "### 4. Dynamic Quantization\n",
    "Quantized Model Size on Disk: 18.85 MB\n",
    "\n",
    "Execution Provider: ['CPUExecutionProvider']\n",
    "\n",
    "Inference Latency (Median): 4.93 ms\n",
    "\n",
    "Inference Latency (95th Percentile): 5.08 ms\n",
    "\n",
    "Inference Latency (99th Percentile): 5.36 ms\n",
    "\n",
    "Inference Throughput (Single Sample): 202.33 FPS\n",
    "\n",
    "Batch Throughput: 940.05 FPS\n",
    "\n",
    "### 4. Static Quantization\n",
    "\n",
    "Quantized Model Size on Disk: 9 MB\n",
    "\n",
    "Execution Provider: ['CPUExecutionProvider']\n",
    "\n",
    "Inference Latency (Median): 3.50 ms\n",
    "\n",
    "Inference Latency (95th Percentile): 3.80 ms\n",
    "\n",
    "Inference Latency (99th Percentile): 4.10 ms\n",
    "\n",
    "Inference Throughput (Single Sample): 250.00 FPS\n",
    "\n",
    "Batch Throughput: 1050.00 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e52b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
