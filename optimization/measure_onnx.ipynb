{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa125c55",
   "metadata": {},
   "source": [
    "\n",
    "# Step 5: Measure Inference Performance of Quantized ONNX Model on CPU\n",
    "\n",
    "This notebook benchmarks the inference performance of different ONNX model variants on CPU, including:\n",
    "- Original FP32 model\n",
    "- Dynamically quantized INT8 model\n",
    "- Statically quantized INT8 model\n",
    "\n",
    "Metrics include:\n",
    "- Average latency per sample (ms)\n",
    "- Throughput (samples/sec)\n",
    "- Model size (MB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b38b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install onnxruntime matplotlib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import onnxruntime as ort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS = {\n",
    "    \"FP32\": \"ssept.onnx\",\n",
    "    \"INT8-Dynamic\": \"ssept_quant_dynamic.onnx\",\n",
    "    \"INT8-Static\": \"ssept_quant_static.onnx\"\n",
    "}\n",
    "\n",
    "INPUT_DIM = 768   # Change to match your model's input dimension\n",
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4568b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_model(model_path, input_dim=768, batch_size=128):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        return None\n",
    "\n",
    "    session = ort.InferenceSession(model_path, providers=[\"CPUExecutionProvider\"])\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    # Latency test (single sample)\n",
    "    latencies = []\n",
    "    for _ in range(100):\n",
    "        dummy_input = np.random.rand(1, input_dim).astype(\"float32\")\n",
    "        start = time.time()\n",
    "        _ = session.run(None, {input_name: dummy_input})\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "    # Throughput test (batch inference)\n",
    "    batch_input = np.random.rand(batch_size, input_dim).astype(\"float32\")\n",
    "    start = time.time()\n",
    "    for _ in range(20):\n",
    "        _ = session.run(None, {input_name: batch_input})\n",
    "    total_time = time.time() - start\n",
    "    throughput = (batch_size * 20) / total_time\n",
    "\n",
    "    return {\n",
    "        \"latency_ms\": np.mean(latencies) * 1000,\n",
    "        \"p95_latency_ms\": np.percentile(latencies, 95) * 1000,\n",
    "        \"throughput\": throughput,\n",
    "        \"model_size_MB\": os.path.getsize(model_path) / 1e6\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eced96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "for name, path in MODELS.items():\n",
    "    print(f\"Testing {name} model...\")\n",
    "    results[name] = benchmark_model(path, INPUT_DIM, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4178ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results).T.round(2)\n",
    "df = df[[\"model_size_MB\", \"latency_ms\", \"p95_latency_ms\", \"throughput\"]]\n",
    "df.columns = [\"Model Size (MB)\", \"Mean Latency (ms)\", \"P95 Latency (ms)\", \"Throughput (samples/sec)\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.plot(kind=\"bar\", figsize=(12, 6), rot=0, title=\"ONNX Model Inference Performance on CPU\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
